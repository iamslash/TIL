
- [References](#references)
- [DeepSeek-V3란 무엇일까?](#deepseek-v3란-무엇일까)
- [MoE(Mixture-of-Experts) 방식이란?](#moemixture-of-experts-방식이란)
- [MLA(Multi-head Latent Attention)란?](#mlamulti-head-latent-attention란)
- [Multi-Token Prediction (MTP)](#multi-token-prediction-mtp)
- [어떻게 이렇게 큰 모델을 효율적으로 학습했나?](#어떻게-이렇게-큰-모델을-효율적으로-학습했나)
  - [FP8(8비트 부동소수점) 훈련](#fp88비트-부동소수점-훈련)
  - [대규모 GPU 병렬화(Parallelism)](#대규모-gpu-병렬화parallelism)
- [학습 후 미세조정(파인튜닝)](#학습-후-미세조정파인튜닝)
  - [지도학습(SFT)](#지도학습sft)
  - [강화학습(RL)](#강화학습rl)
- [결과와 의의](#결과와-의의)
- [한계 및 향후 과제](#한계-및-향후-과제)

-----

# References

- [DeepSeek-V3 | github](https://github.com/deepseek-ai/DeepSeek-V3/tree/main)


# DeepSeek-V3란 무엇일까?

DeepSeek-V3는 "거대언어모델(LLM: Large Language Model)"의 한 종류입니다.

파라미터(모델 내부의 가중치) 수가 총 6710억(=671B) 개에 달하는 매우 거대한 모델이지만,
한 번의 예측(추론) 과정에서 ‘실제로 활성화되는(계산에 참여하는)’ 파라미터 수는 370억(=37B) 정도로 줄였습니다. (이를 Mixture-of-Experts, 즉 ‘여러 전문가 집합’ 방식으로 구현)
이렇게 하면 학습(Training)이나 추론(Inference) 비용을 크게 절약하면서도, 대규모 모델의 성능을 최대한 살릴 수 있습니다.

# MoE(Mixture-of-Experts) 방식이란?
   
보통 거대언어모델은 한 덩어리의 거대한 네트워크가 모든 입력을 통째로 처리합니다(‘Dense 모델’).
MoE 방식은 여러 ‘전문가(Expert)’를 준비해두고, 들어오는 문장(토큰)마다 “어떤 전문가가 가장 적합한지” 골라서 계산하는 구조입니다.
예를 들어, ‘수학에 특화된 전문가’, ‘프로그래밍 코드에 특화된 전문가’ 등이 따로 있고, 토큰마다 해당 토큰을 처리하기에 좋은 전문가들을 골라서 사용합니다.
이렇게 하면 한 번 계산할 때 ‘전문가 전체(수백 또는 수천 명?)’가 아니라 **‘일부 전문가’**만 이용하기 때문에 활성화되는 파라미터 수를 줄일 수 있습니다.
DeepSeek-V3에서는 256개의 ‘전문가’가 있고, 입력 토큰 하나마다 그 중 8개만 골라 계산합니다.

# MLA(Multi-head Latent Attention)란?

일반적으로 ‘트랜스포머(Transformer)’ 모델에서는 ‘어텐션(Attention)’이라 불리는 핵심 기법을 씁니다.
그런데 모델이 매우 커지면, 어텐션 과정에서 Key-Value(KV) 캐시를 저장해야 하는데, 이게 메모리를 많이 차지하게 됩니다.
MLA는 Key-Value를 압축해서 보관하도록 고안된 방식입니다.
즉, 이 키/밸류를 ‘크게 줄인(latent) 벡터’로 변환해두고, 필요할 때만 다시 복원해 씁니다.
이를 통해 추론 시 필요한 메모리가 크게 줄어들고, 추론 속도도 빨라집니다.

# Multi-Token Prediction (MTP)

보통 ‘다음 단어(토큰) 예측’이라고 하면 한 번에 ‘다음 1개의 토큰’을 맞히도록 학습합니다.
DeepSeek-V3는 한 걸음 더 나아가, 한 번에 다음 토큰 2개를 동시에 예측하도록 학습합니다(Multi-Token Prediction).
이렇게 하면 훈련을 더 효율적으로 할 수 있고, 추론에서도 ‘추측 예측(Speculative Decoding)’ 기법을 활용해 속도를 올릴 수 있습니다.
예: “이 문장은 …” 하면서 한 번에 두 단어씩 미리 추정해보는 식으로 진행.

# 어떻게 이렇게 큰 모델을 효율적으로 학습했나?

## FP8(8비트 부동소수점) 훈련

보통 대규모 모델을 학습할 때는 16비트(BF16)나 32비트(FP32)를 많이 씁니다.
DeepSeek-V3에서는 FP8(8비트) 정밀도로 연산을 실행할 수 있게 만들었습니다.
대신 필요한 곳(예: 민감한 연산)에서는 BF16이나 FP32 등을 잘 섞어서, 정확도를 유지하도록 했습니다.
이렇게 하면 연산 속도가 빨라지고, 메모리 사용량도 감소합니다.

## 대규모 GPU 병렬화(Parallelism)
약 2000장 이상의 NVIDIA H800 GPU로 모델을 학습했습니다.
Pipeline Parallelism(PP), Expert Parallelism(EP), Data Parallelism(DP) 등을 결합해, 수천 개의 GPU가 동시에 효율적으로 일하도록 설계했습니다.
특히, DualPipe라는 기법을 활용해, ‘앞방향(Forward)’과 ‘뒷방향(Backward)’ 연산 사이의 공백시간(Bubble)을 크게 줄여서, 학습 속도를 높였습니다.
또, 통신 과정(all-to-all)도 ‘계산 중간’에 겹쳐서(Overlap) 실행해, 통신 지연을 최소화했습니다.
이 덕분에 14.8조(=14.8T) 개의 토큰을 학습하는 데 드는 비용을 상당히 낮출 수 있었다고 합니다.
논문에서는 **“총 278.8만 GPU시간(2.788M GPU Hours) 정도면 완전학습이 가능”**하다고 주장합니다.
(이는 GPU 대여비를 시간당 약 2달러로 가정하면 약 557만 달러 정도로 추산)

# 학습 후 미세조정(파인튜닝)

## 지도학습(SFT)
먼저, 사람이나 다른 모델이 만든 질의-응답(Instruction) 데이터 150만 건을 모아서 **SFT(Supervised Fine-Tuning)**를 진행했습니다.
이 때, 사고 과정을 너무 길게 쓰는(R1 모델 등) 데이터를 적절히 “필요한 만큼”만 받아들여, 답변이 길어지기만 하고 핵심이 흐려지는 문제를 조정했습니다.
## 강화학습(RL)
추가로, **강화학습(RL)**을 통해, 모델이 사용자 질의에 맞는 답변(‘좋은’ 답변)을 생성하도록 보상(Reward)을 줬습니다.
예컨대, 수학 문제는 정답이 뚜렷하므로, 정답이 맞으면 높은 점수, 틀리면 낮은 점수를 주는 식으로 모델을 학습시켰습니다.
그 외 주관적 질문에 대해서는 모델 기반의 판별(Reward Model)로 ‘좋은 답’ 점수를 매기고, RL을 수행했습니다.

# 결과와 의의
영어·중국어 등 여러 분야에서 성능이 매우 좋습니다.
수학(MATH, AIME), 프로그래밍(Codeforces, HumanEval 등) 분야에서 특히 우수한 결과를 보이며, 이전 오픈소스 모델 대비 큰 향상을 보여줍니다.
영어 지식 문제(MMLU, GPQA)나 긴 지문 처리(최대 128K 토큰)에서도 경쟁력 있는 성능을 냅니다.
상용 모델인 GPT-4나 Claude-3.5와도 근접하거나 일부 영역에서는 비슷한 수준의 성능을 낸다고 보고합니다.
그럼에도 학습 비용이 상대적으로 저렴하여, “성능과 비용의 균형”을 잘 맞춘 점이 주목할 만합니다.

# 한계 및 향후 과제
매우 큰 모델이기 때문에, 최적의 추론(서비스) 환경을 구축하려면 아직도 상당히 많은 GPU 노드가 필요합니다. 작은 팀이나 개인에게는 부담이 될 수 있습니다.
모델 속도 역시 기존 모델보다 빨라졌으나, 여전히 개선 여지가 있습니다(예: 더 빠른 디코딩, 더 나은 통신 최적화).
추론 과정에서 전문가를 라우팅하는 방식 등이 더욱 발전하면, 비용 절감과 속도 향상 가능성이 큽니다.
앞으로는 더 다양한 데이터, 더 효율적인 학습 기법을 도입하여 **“보다 일반적인 지능(AGI에 가까운 LLM)”**에 한 걸음씩 다가가는 것을 목표로 합니다.
정리
DeepSeek-V3는 수백억~수천억 대의 파라미터를 “전부 다 쓰지 않고”, **‘필요할 때만 일부 전문가를 선택’**해서 쓰는 MoE(Mixture-of-Experts) 구조를 택해, 성능과 비용 사이의 균형을 크게 개선한 차세대 거대언어모델입니다.
여기에 **MLA(Multi-head Latent Attention)**로 ‘메모리 효율’을 높이고, FP8 정밀도를 적극 활용해 학습 속도를 올리는 동시에 메모리 사용량을 줄였습니다.
또, Multi-Token Prediction으로 한 번에 다음 토큰 2개를 예측하여 학습 효율을 높였고, 추가적인 RL(강화학습) 과정을 통해 사용자 요구에 맞춰 응답하도록 맞춤형 학습을 진행했습니다.
결과적으로, 수학·프로그래밍·영어·중국어 등 여러 영역에서 이전보다 훨씬 향상된 성능을 달성하면서도, 거대한 LLM 학습에 드는 비용이 한층 경제적이라는 점이 큰 특징입니다.

이 연구는 대규모 GPU 클러스터와 정교한 병렬화·통신 최적화를 통해 단기간에 대량의 데이터를 처리했고, 결국 **“오픈소스 LLM”**으로서 GPT-4, Claude-3.5 같은 최신 폐쇄형 모델에 성능 면에서 근접할 수 있다는 점을 시사합니다. 앞으로도 더 효율적인 아키텍처, 새로운 학습 기법, 다양한 데이터를 통해 AI 모델을 발전시키는 계기가 될 것으로 기대됩니다.