- [Materials](#materials)

----

# Materials

* [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
* [Pytorch Transformers from Scratch (Attention is all you need) | youtube](https://www.youtube.com/watch?v=U0s0f995w14)
  * [pytorch src](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py)
* [Visual Guide to Transformer Neural Networks - (Episode 1) Position Embeddings | youtube](https://www.youtube.com/watch?v=dichIcUZfOw)
  * [Visual Guide to Transformer Neural Networks - (Episode 2) Multi-Head & Self-Attention | youtube](https://www.youtube.com/watch?v=mMa2PmYJlCo)
  * [Visual Guide to Transformer Neural Networks - (Episode 3) Decoder’s Masked Attention | youtube](https://www.youtube.com/watch?v=gJ9kaJsE78k)
* [[딥러닝 기계 번역] Transformer: Attention Is All You Need (꼼꼼한 딥러닝 논문 리뷰와 코드 실습) | youtube](https://www.youtube.com/watch?v=AA621UofTUA)
