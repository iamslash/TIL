- [Materials](#materials)
- [Getting started](#getting-started)
- [Deployment](#deployment)
- [Neural net foundations](#neural-net-foundations)
- [Natural Language (NLP)](#natural-language-nlp)
- [From-scratch model](#from-scratch-model)
- [Random forests](#random-forests)
- [Collaborative filtering](#collaborative-filtering)
- [Convolutions (CNNs)](#convolutions-cnns)
- [overview](#overview)
- [Stable Diffusion](#stable-diffusion)
- [Diving Deeper](#diving-deeper)
- [Matrix multiplication](#matrix-multiplication)
- [Mean shift clustering](#mean-shift-clustering)
- [Backpropagation \& MLP](#backpropagation--mlp)
- [Backpropagation](#backpropagation)
- [Autoencoders](#autoencoders)
- [The Learner framework](#the-learner-framework)
- [Initialization/normalization](#initializationnormalization)
- [Accelerated SGD \& ResNets](#accelerated-sgd--resnets)
- [DDPM and Dropout](#ddpm-and-dropout)
- [Mixed Precision](#mixed-precision)
- [DDIM](#ddim)
- [Karras et al (2022)](#karras-et-al-2022)
- [Super-resolution](#super-resolution)
- [Attention \& transformers](#attention--transformers)
- [Latent diffusion](#latent-diffusion)

-----

# Materials

- [Practical Deep Learning for Coders](https://course.fast.ai/)
  - [notebooks](https://course.fast.ai/Resources/book.html)
  - [The fast.ai course notebooks | github](https://github.com/fastai/course22)


# Getting started



# Deployment

- [Lesson 2: Practical Deep Learning for Coders 2022 | youtube](https://www.youtube.com/watch?v=F4tvM4Vb3A0)
- [Saving a basic fastai model | kaggle](https://www.kaggle.com/code/jhoward/saving-a-basic-fastai-model)
- [Chapter 2, Production | clab](https://colab.research.google.com/github/fastai/fastbook/blob/master/02_production.ipynb)

# Neural net foundations

- [Lesson 3: Practical Deep Learning for Coders 2022 | youtube](https://www.youtube.com/watch?v=hBBOjCiFcuo)
- [course22/04-how-does-a-neural-net-really-work.ipynb](https://github.com/fastai/course22/blob/master/04-how-does-a-neural-net-really-work.ipynb)
- [Chapter 4, MNIST Basics | colab](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb)
- [HuggingFace Spaces Pets repository | higgingface](https://huggingface.co/spaces/jph00/pets/tree/main)
- [Which image models are best? | kaggle](https://www.kaggle.com/code/jhoward/which-image-models-are-best/)
- [How does a neural net really work? | kaggle](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work)
- [Titanic - Machine Learning from Disaster | kaggle](https://www.kaggle.com/competitions/titanic/)

# Natural Language (NLP)

- [Lesson 4: Practical Deep Learning for Coders 2022](https://www.youtube.com/watch?v=toUgBQv1BT8)
- [Chapter 10, NLP | colab](https://colab.research.google.com/github/fastai/fastbook/blob/master/10_nlp.ipynb) 
- [Getting started with NLP for absolute beginners | kaggle](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners)

# From-scratch model

- [Lesson 5: Practical Deep Learning for Coders 2022 | youtube](https://www.youtube.com/watch?v=_rXzeWq4C6w)
- [Linear model and neural net from scratch | kaggle](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch)
- [Chapter 4, MNIST Basics | colab](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb)
- [Chapter 9, Tabular | colab](https://colab.research.google.com/github/fastai/fastbook/blob/master/09_tabular.ipynb)

# Random forests

- [Lesson 6: Practical Deep Learning for Coders 2022 | youtube](https://www.youtube.com/watch?v=AdhG64NF76E)
- [How random forests really work | kaggle](https://www.kaggle.com/code/jhoward/how-random-forests-really-work/)
- [First Steps: Road to the Top, Part 1 | kaggle](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1)

# Collaborative filtering
# Convolutions (CNNs)
# overview
# Stable Diffusion
# Diving Deeper
# Matrix multiplication
# Mean shift clustering
# Backpropagation & MLP
# Backpropagation
# Autoencoders
# The Learner framework
# Initialization/normalization
# Accelerated SGD & ResNets
# DDPM and Dropout
# Mixed Precision
# DDIM
# Karras et al (2022)
# Super-resolution
# Attention & transformers
# Latent diffusion
